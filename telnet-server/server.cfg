[general]
debug = false
port = 23
default_language = en
ai_websocket_uri = wss://ollama-server:50000/ai
welcome_message = Telnet Live Wikipedia with AI assistant
# delete this line to get some far-out default system message that tries to make 300MB model understand reason
system_text = ONLY answer in English language. The name is MULTIVAC. Provide succinct answers. Replies must be in English.
ai_activated = true 

[ollama]
debug = false
port = 50000
auth_token = PLEASECHANGEOMGIFTHISPORTISEXPOSEDHAXORWILLGETYOU
model = smollm2:360m
# if this is localhost, the model will download and run inside ollama docker
ollama_uri = http://localhost:11434/api

[internal]
# Possibly more settings for future expansion
